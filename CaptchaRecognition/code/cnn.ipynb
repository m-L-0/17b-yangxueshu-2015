{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from read_data import dataset2\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义存储地址与名称\n",
    "CNN = '/home/aa/CaptchaRecognition/data/cnn'\n",
    "cnn = 'Captcha'\n",
    "#定义模型文件所在的文件夹，若不存在则自动创建\n",
    "ckpt = tf.train.latest_checkpoint(CNN)\n",
    "if not ckpt:\n",
    "    if not os.path.exists(CNN):\n",
    "        os.mkdir(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络（有正则化的添加与使用）\n",
    "def weight_variable(shape):  \n",
    "    # 使用截断正态分布生成卷积核\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)  \n",
    "    return tf.Variable(initial)  \n",
    "  \n",
    "\n",
    "def bias_variable(shape):  \n",
    "    # 使用relu激活函数，用一个正偏置值较准\n",
    "    initial = tf.constant(0.1, shape=shape)  \n",
    "    return tf.Variable(initial)  \n",
    "  \n",
    "\n",
    "def conv2d(x, W, strides=[1, 1, 1, 1]):  \n",
    "    # 定义卷积层\n",
    "    return tf.nn.conv2d(x, W, strides=strides, padding='SAME')   \n",
    "\n",
    "\n",
    "# min_next_batch_tfr(随机批次载入数据)\n",
    "def min_next_batch_tfr(image, label, num=50, num1=500): \n",
    "    images = np.zeros((num, 2240))\n",
    "    labels = np.zeros((num, 44))\n",
    "    for i in range(num):\n",
    "        temp = random.randint(0, num1-1)\n",
    "        images[i, :] = image[temp]\n",
    "        labels[i, :] = label[temp]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2240])\n",
    "y_1 = tf.placeholder(tf.float32, [None, 11])\n",
    "y_2 = tf.placeholder(tf.float32, [None, 11])\n",
    "y_3 = tf.placeholder(tf.float32, [None, 11])\n",
    "y_4 = tf.placeholder(tf.float32, [None, 11])\n",
    "\n",
    "with tf.variable_scope('model') as scope:\n",
    "    # 格式转换\n",
    "    x_image = tf.reshape(x, [-1, 40, 56, 1])\n",
    "    \n",
    "    # conv1，卷积核尺寸为2*2, 通道数为1，输出通道为32\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        W_conv1 = weight_variable([2, 2, 1, 32])  \n",
    "        b_conv1 = bias_variable([32])  \n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) \n",
    "        \n",
    "    # conv2，卷积核尺寸为2*2, 通道数为32，输出通道为48\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        W_conv2 = weight_variable([2, 2, 32, 48])  \n",
    "        b_conv2 = bias_variable([48])  \n",
    "        h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, [1, 2, 2, 1]) + b_conv2) \n",
    "\n",
    "    # conv3，卷积核尺寸为2*2, 输入通道为48，输出通道为64\n",
    "    with tf.variable_scope('conv3') as scope:\n",
    "        W_conv3 = weight_variable([2, 2, 48, 64])  \n",
    "        b_conv3 = bias_variable([64])  \n",
    "        h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3) + b_conv3)  \n",
    "\n",
    "    # conv4，卷积核尺寸为2*2, 通道数为64，输出通道为72\n",
    "    with tf.variable_scope('conv4') as scope:\n",
    "        W_conv4 = weight_variable([2, 2, 64, 72])  \n",
    "        b_conv4 = bias_variable([72])  \n",
    "        h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, [1, 2, 2, 1]) + b_conv4) \n",
    "\n",
    "    # conv5，卷积核尺寸为2*2, 输入通道为72，输出通道为96\n",
    "    with tf.variable_scope('conv5') as scope:\n",
    "        W_conv5 = weight_variable([2, 2, 72, 96])  \n",
    "        b_conv5 = bias_variable([96])  \n",
    "        h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5) + b_conv5)\n",
    "        \n",
    "    # conv6，卷积核尺寸为2*2, 通道数为96，输出通道为128\n",
    "    with tf.variable_scope('conv6') as scope:\n",
    "        W_conv6 = weight_variable([2, 2, 96, 128])  \n",
    "        b_conv6 = bias_variable([128])  \n",
    "        h_conv6 = tf.nn.relu(conv2d(h_conv5, W_conv6, [1, 2, 2, 1]) + b_conv6)  \n",
    "        \n",
    "    # conv7，卷积核尺寸为2*2, 通道数为128，输出通道为256\n",
    "    with tf.variable_scope('conv7') as scope:\n",
    "        W_conv7 = weight_variable([2, 2, 128, 256])  \n",
    "        b_conv7 = bias_variable([256])  \n",
    "        h_conv7 = tf.nn.relu(conv2d(h_conv6, W_conv7) + b_conv7)  \n",
    "        \n",
    "    # conv8，卷积核尺寸为2*2, 通道数为256，输出通道为256\n",
    "    with tf.variable_scope('conv8') as scope:\n",
    "        W_conv8 = weight_variable([2, 2, 256, 256])  \n",
    "        b_conv8 = bias_variable([256])  \n",
    "        h_conv8 = tf.nn.relu(conv2d(h_conv7, W_conv8) + b_conv8)  \n",
    "        \n",
    "    # conv9，卷积核尺寸为2*2, 通道数为256，输出通道为512\n",
    "    with tf.variable_scope('conv9') as scope:\n",
    "        W_conv9 = weight_variable([2, 2, 256, 512])  \n",
    "        b_conv9 = bias_variable([512])  \n",
    "        h_conv9 = tf.nn.relu(conv2d(h_conv8, W_conv9) + b_conv9)  \n",
    "        \n",
    "    # conv10，卷积核尺寸为2*2, 通道数为512，输出通道为256\n",
    "    with tf.variable_scope('conv10') as scope:\n",
    "        W_conv10 = weight_variable([2, 2, 512, 256])  \n",
    "        b_conv10 = bias_variable([256])  \n",
    "        h_conv10 = tf.nn.relu(conv2d(h_conv9, W_conv10) + b_conv10)  \n",
    "        \n",
    "    # pool,转化为1*1\n",
    "    with tf.variable_scope('pool') as scope:\n",
    "        pool = tf.nn.avg_pool(\n",
    "            h_conv10, \n",
    "            [1, 5, 7, 1], \n",
    "            [1, 5, 7, 1], \n",
    "            padding='VALID')\n",
    "        flatten = tf.reshape(pool, shape=[-1, 256])\n",
    "        \n",
    "    # fc21,输入256维，输出11维，预测标签第一位\n",
    "    with tf.variable_scope('fc21') as scope:\n",
    "        W_fc21 = weight_variable([256,11])\n",
    "        b_fc21 = bias_variable([11])   \n",
    "        y_conv1 =tf.matmul(flatten, W_fc21) + b_fc21\n",
    "    # fc22,输入256维，输出11维，预测标签第二位\n",
    "    with tf.variable_scope('fc22') as scope:\n",
    "        W_fc22 = weight_variable([256,11])\n",
    "        b_fc22 = bias_variable([11])   \n",
    "        y_conv2 = tf.matmul(flatten, W_fc22) + b_fc22\n",
    "    # fc23,输入256维，输出11维，预测标签第三位\n",
    "    with tf.variable_scope('fc23') as scope:\n",
    "        W_fc23 = weight_variable([256,11])\n",
    "        b_fc23 = bias_variable([11])\n",
    "        y_conv3 = tf.matmul(flatten, W_fc23) + b_fc23\n",
    "    # fc24,输入256维，输出11维，预测标签第四位\n",
    "    with tf.variable_scope('fc24') as scope:\n",
    "        W_fc24 = weight_variable([256,11])\n",
    "        b_fc24 = bias_variable([11])   \n",
    "        y_conv4 = tf.matmul(flatten, W_fc24) + b_fc24\n",
    "\n",
    "\n",
    "with tf.variable_scope('calculation') as scope:\n",
    "    # 损失函数，交叉熵\n",
    "    cross_entropy11 = tf.nn.softmax_cross_entropy_with_logits(labels=y_1, logits=y_conv1)\n",
    "    cross_entropy22 = tf.nn.softmax_cross_entropy_with_logits(labels=y_2, logits=y_conv2)\n",
    "    cross_entropy33 = tf.nn.softmax_cross_entropy_with_logits(labels=y_3, logits=y_conv3)\n",
    "    cross_entropy44 = tf.nn.softmax_cross_entropy_with_logits(labels=y_4, logits=y_conv4)\n",
    "    cross_entropy1 = tf.reduce_mean(cross_entropy11)\n",
    "    cross_entropy2 = tf.reduce_mean(cross_entropy22)\n",
    "    cross_entropy3 = tf.reduce_mean(cross_entropy33)\n",
    "    cross_entropy4 = tf.reduce_mean(cross_entropy44)\n",
    "    cross_entropy = cross_entropy1 + cross_entropy2 + cross_entropy3 + cross_entropy4\n",
    "    \n",
    "    # 使用adam优化\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "    # 正确率计算\n",
    "    correct_prediction1 = tf.equal(tf.argmax(y_conv1, 1), tf.argmax(y_1, 1))  \n",
    "    accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))\n",
    "    correct_prediction2 = tf.equal(tf.argmax(y_conv2, 1), tf.argmax(y_2, 1))\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n",
    "    correct_prediction3 = tf.equal(tf.argmax(y_conv3, 1), tf.argmax(y_3, 1))\n",
    "    accuracy3 = tf.reduce_mean(tf.cast(correct_prediction3, tf.float32))\n",
    "    correct_prediction4 = tf.equal(tf.argmax(y_conv4, 1), tf.argmax(y_4, 1))\n",
    "    accuracy4 = tf.reduce_mean(tf.cast(correct_prediction4, tf.float32))\n",
    "    \n",
    "    acce = tf.reduce_mean([accuracy1, accuracy2, accuracy3, accuracy4])\n",
    "    corr = tf.reduce_all([correct_prediction1, correct_prediction2, correct_prediction3, correct_prediction4], 0)\n",
    "    acc = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "    \n",
    "    # 提取摘要\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    tf.summary.scalar('accuracy', acc)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数数量为：1568612\n"
     ]
    }
   ],
   "source": [
    "# 打印模型参数数量\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "def get_num_params():\n",
    "    num_params = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        shape = variable.get_shape()\n",
    "        num_params += reduce(mul, [dim.value for dim in shape], 1)\n",
    "    return num_params\n",
    "\n",
    "print('参数数量为：%d' %get_num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "done\n",
      "training...\n",
      "done\n",
      "training...\n",
      "done\n",
      "training...\n",
      "done\n",
      "training...\n",
      "done\n",
      "training...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "with tf.variable_scope('load_data') as scope:\n",
    "    train_i = np.empty((4720*4, 2240))\n",
    "    train_l = np.empty((4720*4, 44))\n",
    "    for w in range(4):\n",
    "        train_i[0+4720*w:4720+4720*w], train_l[0+4720*w:4720+4720*w] = dataset2(\n",
    "            ('train%d' %(w+1)),4720)\n",
    "    validation_i,validation_l = dataset2('validation1',2360)\n",
    "    test_i,test_l = dataset2('test1',2360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train loss is 34.881283, validation loss 19.219315\n",
      "验证码字符识别正确率 0.241750\n",
      "验证码识别正确率 0.000000\n",
      "平均正确率 0.120875\n",
      "-----------------------------------------------------------\n",
      "step 1, train loss is 7.470591, validation loss 7.490627\n",
      "验证码字符识别正确率 0.409250\n",
      "验证码识别正确率 0.025000\n",
      "平均正确率 0.217125\n",
      "-----------------------------------------------------------\n",
      "step 2, train loss is 7.547095, validation loss 7.452349\n",
      "验证码字符识别正确率 0.420750\n",
      "验证码识别正确率 0.038000\n",
      "平均正确率 0.229375\n",
      "-----------------------------------------------------------\n",
      "step 3, train loss is 7.432042, validation loss 7.562891\n",
      "验证码字符识别正确率 0.397000\n",
      "验证码识别正确率 0.028000\n",
      "平均正确率 0.212500\n",
      "-----------------------------------------------------------\n",
      "step 4, train loss is 7.585989, validation loss 7.366376\n",
      "验证码字符识别正确率 0.419250\n",
      "验证码识别正确率 0.037000\n",
      "平均正确率 0.228125\n",
      "-----------------------------------------------------------\n",
      "step 5, train loss is 7.527457, validation loss 7.417470\n",
      "验证码字符识别正确率 0.407000\n",
      "验证码识别正确率 0.030000\n",
      "平均正确率 0.218500\n",
      "-----------------------------------------------------------\n",
      "step 6, train loss is 7.341599, validation loss 7.525474\n",
      "验证码字符识别正确率 0.398000\n",
      "验证码识别正确率 0.028000\n",
      "平均正确率 0.213000\n",
      "-----------------------------------------------------------\n",
      "step 7, train loss is 6.832863, validation loss 7.688411\n",
      "验证码字符识别正确率 0.394000\n",
      "验证码识别正确率 0.027000\n",
      "平均正确率 0.210500\n",
      "-----------------------------------------------------------\n",
      "step 8, train loss is 7.578280, validation loss 7.430042\n",
      "验证码字符识别正确率 0.397000\n",
      "验证码识别正确率 0.031000\n",
      "平均正确率 0.214000\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，训练过程中每一百次插播验证集当前识别率\n",
    "with tf.Session() as sess: \n",
    "    # 运行会话\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 变量定义\n",
    "    step = 0\n",
    "    losslist = []\n",
    "    minloss = 10000\n",
    "    # 若模型存在，自动加载模型进会话\n",
    "    ckpt = tf.train.latest_checkpoint(CNN)\n",
    "    if ckpt:\n",
    "        saver.restore(sess=sess,save_path=ckpt)\n",
    "        step = int(ckpt[len(os.path.join(CNN, cnn)) + 1:])\n",
    "    ckptname=os.path.join(CNN, cnn)\n",
    "    writer1 = tf.summary.FileWriter('./train_graphs', filename_suffix='.file')\n",
    "    writer2 = tf.summary.FileWriter('./validation_graphs', filename_suffix='.file')\n",
    "    writer1.add_graph(tf.get_default_graph())\n",
    "    # 开启线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 训练\n",
    "    for i in range(45000):\n",
    "        im, l = min_next_batch_tfr(train_i, train_l, 150, 4720*4)\n",
    "        l1=l[:,0:11]\n",
    "        l2=l[:,11:22]\n",
    "        l3=l[:,22:33]\n",
    "        l4=l[:,33:44]\n",
    "        loss_, _=sess.run([cross_entropy, train_step], feed_dict={\n",
    "                              x: im, y_1: l1,y_2: l2, y_3: l3, y_4: l4\n",
    "                          })\n",
    "        # 每训练3000个用验证集测试150个\n",
    "        if i%20 ==0:\n",
    "            # 训练代价摘要\n",
    "            m1 = sess.run(merged, feed_dict={x: im, y_1: l1,y_2: l2, y_3: l3, y_4: l4})\n",
    "            writer1.add_summary(m1, global_step=i)\n",
    "            v_i, v_l = min_next_batch_tfr(validation_i,validation_l, 1000, 2360)\n",
    "            v_l1=v_l[:,0:11]\n",
    "            v_l2=v_l[:,11:22]\n",
    "            v_l3=v_l[:,22:33]\n",
    "            v_l4=v_l[:,33:44]\n",
    "            m2, accev, accu, loss = sess.run([merged, acce, acc, cross_entropy], \n",
    "                feed_dict={\n",
    "                    x: v_i, y_1: v_l1, y_2: v_l2, y_3: v_l3, y_4: v_l4\n",
    "                })\n",
    "            writer2.add_summary(m2, global_step=i)\n",
    "            print(\"step %d, train loss is %f, validation loss %f\" % (i//20, loss_, loss))\n",
    "            print(\"验证码字符识别正确率 %f\" % accev)\n",
    "            print(\"验证码识别正确率 %f\" % accu)\n",
    "            print(\"平均正确率 %f\" % np.mean([accu,accev]))\n",
    "            print(\"-----------------------------------------------------------\")\n",
    "            losslist.append(loss)\n",
    "        # 保存损失最低的模型\n",
    "        if minloss > loss:\n",
    "            minloss = loss\n",
    "            saver.save(sess,ckptname,global_step=150*i)\n",
    "        if losslist[-1] > minloss and losslist[-2] > minloss and losslist[-3] > minloss and losslist[-4] > minloss:\n",
    "            break\n",
    "\n",
    "    coord.request_stop() \n",
    "    coord.join(threads)\n",
    "    writer1.close()\n",
    "    writer2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aa/CaptchaRecognition/data/cnn/Captcha-168000\n",
      "训练集验证码识别正确率 0.743400\n",
      "验证集验证码识别正确率 0.605508\n",
      "测试集验证码识别正确率 0.590678\n"
     ]
    }
   ],
   "source": [
    "# 模型在各个数据集（训练集、验证集、测试集）上正确率的期望\n",
    "with tf.Session() as sess: \n",
    "    # 运行会话\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 加载模型\n",
    "    ckpt = tf.train.latest_checkpoint(CNN)\n",
    "    if ckpt:\n",
    "        saver.restore(sess=sess,save_path=ckpt)\n",
    "        step = int(ckpt[len(os.path.join(CNN, cnn)) + 1:])\n",
    "    ckptname=os.path.join(CNN, cnn)\n",
    "    # 开启线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    # 训练集\n",
    "    im, tr_l = min_next_batch_tfr(train_i, train_l, 5000, 4720*4)\n",
    "    tr_l1 = tr_l[:,0:11]\n",
    "    tr_l2 = tr_l[:,11:22]\n",
    "    tr_l3 = tr_l[:,22:33]\n",
    "    tr_l4 = tr_l[:,33:44]\n",
    "    traccu = sess.run(acc, \n",
    "        feed_dict={\n",
    "            x: im, y_1: tr_l1, y_2: tr_l2, y_3: tr_l3, y_4: tr_l4\n",
    "        })\n",
    "    # 验证集\n",
    "    va_l1 = validation_l[:,0:11]\n",
    "    va_l2 = validation_l[:,11:22]\n",
    "    va_l3 = validation_l[:,22:33]\n",
    "    va_l4 = validation_l[:,33:44]\n",
    "    vaccu = sess.run(acc, \n",
    "        feed_dict={\n",
    "            x: validation_i, y_1: va_l1, y_2: va_l2, y_3: va_l3, y_4: va_l4\n",
    "        })\n",
    "    # 测试集\n",
    "    t_l1 = test_l[:,0:11]\n",
    "    t_l2 = test_l[:,11:22]\n",
    "    t_l3 = test_l[:,22:33]\n",
    "    t_l4 = test_l[:,33:44]\n",
    "    teaccu = sess.run(acc, \n",
    "        feed_dict={\n",
    "            x: test_i, y_1: t_l1, y_2: t_l2, y_3: t_l3, y_4: t_l4\n",
    "        })\n",
    "    print(\"训练集验证码识别正确率 %f\" % traccu)\n",
    "    print(\"验证集验证码识别正确率 %f\" % vaccu)\n",
    "    print(\"测试集验证码识别正确率 %f\" % teaccu)\n",
    "\n",
    "    coord.request_stop() \n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/aa/CaptchaRecognition/data/cnn/Captcha-168000\n",
      "测试集验证码字符识别正确率 0.856674\n",
      "测试集验证码识别正确率 0.590678\n",
      "测试集平均正确率 0.723676\n"
     ]
    }
   ],
   "source": [
    "# 测试集测试泛化能力\n",
    "with tf.Session() as sess: \n",
    "    # 运行会话\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 加载模型\n",
    "    ckpt = tf.train.latest_checkpoint(CNN)\n",
    "    if ckpt:\n",
    "        saver.restore(sess=sess,save_path=ckpt)\n",
    "        step = int(ckpt[len(os.path.join(CNN, cnn)) + 1:])\n",
    "    ckptname=os.path.join(CNN, cnn)\n",
    "    # 开启线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    # 测试\n",
    "    test_i,test_l\n",
    "    t_l1 = test_l[:,0:11]\n",
    "    t_l2 = test_l[:,11:22]\n",
    "    t_l3 = test_l[:,22:33]\n",
    "    t_l4 = test_l[:,33:44]\n",
    "    accev, accu = sess.run([acce, acc], \n",
    "        feed_dict={\n",
    "            x: test_i, y_1: t_l1, y_2: t_l2, y_3: t_l3, y_4: t_l4\n",
    "        })\n",
    "    print(\"测试集验证码字符识别正确率 %f\" % accev)\n",
    "    print(\"测试集验证码识别正确率 %f\" % accu)\n",
    "    print(\"测试集平均正确率 %f\" % np.mean([accu,accev]))\n",
    "\n",
    "    coord.request_stop() \n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
